# -*- coding: utf-8 -*-
"""DeiT_Earlyfusion_6channels.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DU7-ngxSRMeC-mPeIxdzfpj8v1s4nEZg
"""

# Mount your Google Drive
from google.colab import drive
drive.mount('/content/drive')

!unzip -q -n "/content/drive/MyDrive/kaggle/cancer2025/multimodal-cancer-classification-challenge-2025.zip" -d "/content/data"

#Helper function that we share between different models
!git clone https://github.com/JoQueckfeldt/multimodal-oral-cancer-clf.git

# Commented out IPython magic to ensure Python compatibility.
# %cd multimodal-oral-cancer-clf

from dataset import EarlyFusionDataset
from helpers import calculate_mean_std, mixup_data, mixup_bce_loss

import torch
import torchvision.transforms as T
import pandas as pd
from torch.utils.data import DataLoader

# example if working in colab and have the data stored in 'data' folder
bf_root = '/content/data/BF/train'  # Brightfield images root directory
fl_root = '/content/data/FL/train'  # Fluorescence images root directory
train_csv_path = '/content/data/train.csv'  # Path to the CSV file with patient data

# create DataFrame with columns ['Name','Diagnosis','patient_id','split']
val_patients_id = ["05", "16", "07", "09"] # patient IDs for validation set
df = pd.read_csv(train_csv_path) # colums: [Name, Diagnosis]. Names are like pat_NN_image_X
df['patient_id'] = df['Name'].apply(lambda x: x.split('_')[1])  # Extract patient_id from Name
df['split'] = df['patient_id'].apply(lambda x: 'val' if x in val_patients_id else 'train') # Assign split based on patient_id


# calculate statistics for normalization based on the images with split='train'
bf_mean, bf_std, fl_mean, fl_std = calculate_mean_std(df, bf_root=bf_root, fl_root=fl_root)

# same transforms (except data mixup) as in Lian et al., "Let it shine: Autofluorescence
# of Papanicolaou-stain improves AI-based cytological oral cancer detection"
bf_transform = T.Compose([
    # pick exactly one of the three with the given probabilities
    T.RandomChoice(
        transforms=[
            T.RandomPosterize(bits=3),
            T.GaussianBlur(kernel_size=5, sigma=1.5),
            T.RandomSolarize(threshold=100),
        ],
        p=[0.4, 0.2, 0.4]
    ),
    T.ColorJitter(brightness=0.5, contrast=0.2, saturation=0.2, hue=0.2),
    T.ToTensor(),
])
fl_transform = T.Compose([
    T.ColorJitter(brightness=0.8, contrast=0.8),
    T.GaussianBlur(kernel_size=5, sigma=(0.3, 3.2)),
    T.ToTensor(),
])
joint_transform = T.Compose([
    T.Resize((224,224)),
    T.RandomHorizontalFlip(p=0.5),
    T.RandomVerticalFlip(p=0.5),
    T.Normalize(mean=bf_mean+fl_mean, std=bf_std+fl_std),
])

# create datasets for training and validation
train_dataset = EarlyFusionDataset(
    df, split='train', bf_root=bf_root, fl_root=fl_root,
    transforms_bf=bf_transform, transforms_fl=fl_transform, transforms_joint=joint_transform
)
# only resize and normalize val data
val_dataset = EarlyFusionDataset(
    df, split='val', bf_root=bf_root, fl_root=fl_root,
    transforms_bf=T.Compose([T.ToTensor()]), transforms_fl=T.Compose([T.ToTensor()]),
    transforms_joint=T.Compose([T.Resize(224), T.Normalize(mean=bf_mean+fl_mean, std=bf_std+fl_std)])
)

print("All patient_ids:", df['patient_id'].unique())
print("Split counts:\n", df['split'].value_counts())
print("Val patient_ids:", df[df['split']=='val']['patient_id'].unique())

import math
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torch.optim import AdamW
from torch.optim.lr_scheduler import OneCycleLR
from sklearn.metrics import roc_auc_score, precision_recall_curve, auc
from transformers import DeiTConfig, DeiTForImageClassification
from copy import deepcopy

# -----------------------------------------------------------------------------
# 1) One epoch of training
# -----------------------------------------------------------------------------
def train_one_epoch(model, loader, optimizer, criterion, device, mixup_alpha=0.8):
    """
    Runs one epoch of training (mixup + BCE).
    Returns average loss over samples.
    """
    model.train()
    running_loss = 0.0
    total_samples = 0

    for x, y in loader:
        x = x.to(device)
        y = y.to(device)

        # mixup
        x_mix, y_a, y_b, lam = mixup_data(x, y, alpha=mixup_alpha)

        optimizer.zero_grad()
        logits = model(x_mix).logits.squeeze(1)  # [B]
        loss   = mixup_bce_loss(logits,
                                y_a.to(device),
                                y_b.to(device),
                                lam,
                                criterion)

        loss.backward()
        optimizer.step()

        batch_size = x.size(0)
        running_loss += loss.item() * batch_size
        total_samples += batch_size

    return running_loss / total_samples


# -----------------------------------------------------------------------------
# 2) One epoch of validation
# -----------------------------------------------------------------------------
def validate_one_epoch(model, loader, criterion, device, threshold=0.5):
    """
    Runs one epoch of validation.
    Returns a dict with:
      - avg_loss
      - accuracy (at given threshold)
      - roc_auc
      - pr_auc
    """
    model.eval()
    running_loss = 0.0
    correct = 0
    total = 0
    all_labels, all_probs = [], []

    with torch.no_grad():
        for x, y in loader:
            x = x.to(device)
            y = y.to(device)

            logits = model(x).logits.squeeze(1)
            loss   = criterion(logits, y)

            probs = torch.sigmoid(logits)
            preds = (probs > threshold).long()

            correct += (preds == y.long()).sum().item()
            total += y.size(0)
            running_loss += loss.item() * y.size(0)

            all_labels.extend(y.cpu().tolist())
            all_probs.extend(probs.cpu().tolist())

    avg_loss = running_loss / total
    accuracy = correct / total

    # ROC-AUC
    roc_auc = roc_auc_score(all_labels, all_probs)
    # PR-AUC
    precision, recall, _ = precision_recall_curve(all_labels, all_probs)
    pr_auc = auc(recall, precision)

    return {
        "avg_loss": avg_loss,
        "accuracy": accuracy,
        "roc_auc": roc_auc,
        "pr_auc": pr_auc
    }


# -----------------------------------------------------------------------------
# 3) Full training loop with checkpointing
# -----------------------------------------------------------------------------
def train_model(model, train_loader, val_loader,
                optimizer, criterion, device,
                num_epochs=20, print_every=1,
                mixup_alpha=0.8,
                checkpoint_path="best_model.pth"):
    """
    Trains for num_epochs, calling train_one_epoch and validate_one_epoch.
    Saves checkpoint whenever val loss decreases.
    Returns history dict.
    """
    best_loss = float("inf")
    history = {
        "train_loss":  [],
        "val_loss":    [],
        "val_acc":     [],
        "val_roc_auc": [],
        "val_pr_auc":  [],
        "lr":          []
    }

    best_state = deepcopy(model.state_dict())

    for epoch in range(1, num_epochs + 1):
        # --- train ---
        train_loss = train_one_epoch(
            model, train_loader, optimizer,
            criterion, device, mixup_alpha
        )

        # --- validate ---
        val_metrics = validate_one_epoch(
            model, val_loader, criterion, device
        )
        val_loss = val_metrics["avg_loss"]

        # record learning rate
        lr = optimizer.param_groups[0]["lr"]

        # append to history
        history["train_loss"].append(train_loss)
        history["val_loss"].append(val_loss)
        history["val_acc"].append(val_metrics["accuracy"])
        history["val_roc_auc"].append(val_metrics["roc_auc"])
        history["val_pr_auc"].append(val_metrics["pr_auc"])
        history["lr"].append(lr)

        # print
        if epoch % print_every == 0:
            print(
                f"Epoch {epoch}/{num_epochs} â€” "
                f"LR: {lr:.6f} | "
                f"Train Loss: {train_loss:.4f} | "
                f"Val Loss: {val_loss:.4f} | "
                f"Val Acc: {val_metrics['accuracy']:.4f} | "
                f"ROC-AUC: {val_metrics['roc_auc']:.4f} | "
                f"PR-AUC: {val_metrics['pr_auc']:.4f}"
            )

        # checkpoint on lowest val loss
        if val_loss < best_loss:
            best_loss = val_loss
            best_state = deepcopy(model.state_dict())
            torch.save({
                "epoch": epoch,
                "model_state": best_state,
                "optimizer_state": optimizer.state_dict(),
                "history": history,
                "best_val_loss": best_loss
            }, checkpoint_path)

    # load best weights
    model.load_state_dict(best_state)
    print(f"\nBest Validation Loss: {best_loss:.4f} (weights loaded from `{checkpoint_path}`)")

    return history

!pip install -q transformers timm

from torch.utils.data import DataLoader

train_loader = DataLoader(
    train_dataset,
    batch_size=256,
    shuffle=True,
    num_workers=12,
    pin_memory=True,
    prefetch_factor=2,
    persistent_workers=True,
)

val_loader = DataLoader(
    val_dataset,
    batch_size=256,
    shuffle=False,
    num_workers=6,
    pin_memory=True,
    prefetch_factor=2,
    persistent_workers=True,
)

#device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

from transformers import DeiTConfig, DeiTForImageClassification


model_name = "facebook/deit-tiny-distilled-patch16-224"

config = DeiTConfig.from_pretrained(model_name)
config.num_channels = 6
config.num_labels   = 1

model = DeiTForImageClassification.from_pretrained(
    model_name,
    config=config,
    ignore_mismatched_sizes=True,
)
model.gradient_checkpointing_enable()
model.to(device)

from torch.optim import AdamW
from torch import nn

# 1) Optimizer & Scheduler
optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=2e-2)
scheduler = build_cosine_scheduler(optimizer, num_epochs=20, len_loader=len(train_loader), warmup_epochs=3)

# 2) Criterion (unchanged)
pos_weight = torch.tensor([1.67], device=device)
criterion  = nn.BCEWithLogitsLoss(pos_weight=pos_weight)

# 3) Mixup Î±
mixup_alpha = 0.3  # try 0.2â€“0.4

# Then call:
history = train_model(
    model,
    train_loader,
    val_loader,
    optimizer,
    criterion,
    device,
    num_epochs=20,
    print_every=1,
    mixup_alpha=mixup_alpha,
    checkpoint_path="best_by_val_loss.pth"
)

#1 attempt - Tiny DeiT, batch size = 64
#Time/epoch = 18 min, T4
#Epoch 1/20 â€” Train Loss: 0.3159 | Val Loss: 0.3025 | Val Acc: 0.8742 | Val AUC: 0.9669
#Epoch 2/20 â€” Train Loss: 0.2092 | Val Loss: 0.6156 | Val Acc: 0.7867 | Val AUC: 0.9347
#Epoch 3/20 â€” Train Loss: 0.1798 | Val Loss: 0.6549 | Val Acc: 0.8164 | Val AUC: 0.9067

#2 attempt - Tiny DeiT, mixup_alpha = 0.3, BCEwithlogitloss(1.5), batch_size = 64
#Time/epoch = 8 min
#Epoch 1/20 â€” Train Loss: 0.5580 | Val Loss: 0.5551 | Val Acc: 0.8100 | Val AUC: 0.9350
#Epoch 2/20 â€” Train Loss: 0.4557 | Val Loss: 0.5543 | Val Acc: 0.8225 | Val AUC: 0.9257
#Epoch 3/20 â€” Train Loss: 0.4366 | Val Loss: 0.4753 | Val Acc: 0.8453 | Val AUC: 0.9563
#Epoch 4/20 â€” Train Loss: 0.4180 | Val Loss: 0.4215 | Val Acc: 0.8739 | Val AUC: 0.9668
#Epoch 5/20 â€” Train Loss: 0.3997 | Val Loss: 0.3511 | Val Acc: 0.8904 | Val AUC: 0.9682
#Epoch 6/20 â€” Train Loss: 0.3896 | Val Loss: 0.4597 | Val Acc: 0.8560 | Val AUC: 0.9521
#Epoch 7/20 â€” Train Loss: 0.3838 | Val Loss: 0.4555 | Val Acc: 0.8504 | Val AUC: 0.9663
#Epoch 8/20 â€” Train Loss: 0.3733 | Val Loss: 0.7472 | Val Acc: 0.7889 | Val AUC: 0.9243

#3 attempt - Tiny DeiT, mixup_alpha = 0.35, BCEwithlogitloss(1.5), batch_size = 256
#Epoch 1/20 â€” LR: 0.000100 | Train Loss: 0.5934 | Val Loss: 0.6114 | Val Acc: 0.8023 | ROC-AUC: 0.9101 | PR-AUC: 0.8656
#Epoch 2/20 â€” LR: 0.000100 | Train Loss: 0.4864 | Val Loss: 0.5196 | Val Acc: 0.8265 | ROC-AUC: 0.9171 | PR-AUC: 0.8718
#Epoch 3/20 â€” LR: 0.000100 | Train Loss: 0.4486 | Val Loss: 0.5607 | Val Acc: 0.8196 | ROC-AUC: 0.9215 | PR-AUC: 0.8803
#Epoch 4/20 â€” LR: 0.000100 | Train Loss: 0.4601 | Val Loss: 0.5096 | Val Acc: 0.8373 | ROC-AUC: 0.9332 | PR-AUC: 0.9010
#Epoch 5/20 â€” LR: 0.000100 | Train Loss: 0.4377 | Val Loss: 0.4455 | Val Acc: 0.8537 | ROC-AUC: 0.9296 | PR-AUC: 0.8912
#Epoch 6/20 â€” LR: 0.000100 | Train Loss: 0.4224 | Val Loss: 0.4083 | Val Acc: 0.8767 | ROC-AUC: 0.9528 | PR-AUC: 0.9279
#Epoch 7/20 â€” LR: 0.000100 | Train Loss: 0.4242 | Val Loss: 0.5988 | Val Acc: 0.8203 | ROC-AUC: 0.9362 | PR-AUC: 0.8974
#Epoch 8/20 â€” LR: 0.000100 | Train Loss: 0.4106 | Val Loss: 0.3874 | Val Acc: 0.8746 | ROC-AUC: 0.9446 | PR-AUC: 0.9179
#Epoch 9/20 â€” LR: 0.000100 | Train Loss: 0.4177 | Val Loss: 0.4808 | Val Acc: 0.8530 | ROC-AUC: 0.9444 | PR-AUC: 0.9177
#Epoch 10/20 â€” LR: 0.000100 | Train Loss: 0.4087 | Val Loss: 0.5271 | Val Acc: 0.8438 | ROC-AUC: 0.9396 | PR-AUC: 0.9107
#Epoch 11/20 â€” LR: 0.000100 | Train Loss: 0.4093 | Val Loss: 0.5141 | Val Acc: 0.8543 | ROC-AUC: 0.9430 | PR-AUC: 0.9124
#Epoch 12/20 â€” LR: 0.000100 | Train Loss: 0.3910 | Val Loss: 0.5610 | Val Acc: 0.8335 | ROC-AUC: 0.9425 | PR-AUC: 0.9174
#Epoch 13/20 â€” LR: 0.000100 | Train Loss: 0.4069 | Val Loss: 0.5388 | Val Acc: 0.8407 | ROC-AUC: 0.9338 | PR-AUC: 0.9101
#Epoch 14/20 â€” LR: 0.000100 | Train Loss: 0.3927 | Val Loss: 0.5011 | Val Acc: 0.8460 | ROC-AUC: 0.9271 | PR-AUC: 0.8938
#Epoch 15/20 â€” LR: 0.000100 | Train Loss: 0.3977 | Val Loss: 0.5413 | Val Acc: 0.8400 | ROC-AUC: 0.9361 | PR-AUC: 0.9118
#Epoch 16/20 â€” LR: 0.000100 | Train Loss: 0.4005 | Val Loss: 0.6061 | Val Acc: 0.8220 | ROC-AUC: 0.9308 | PR-AUC: 0.8959
#Epoch 17/20 â€” LR: 0.000100 | Train Loss: 0.3931 | Val Loss: 0.6090 | Val Acc: 0.8304 | ROC-AUC: 0.9269 | PR-AUC: 0.9045
#Epoch 18/20 â€” LR: 0.000100 | Train Loss: 0.3460 | Val Loss: 0.5928 | Val Acc: 0.8330 | ROC-AUC: 0.9328 | PR-AUC: 0.9042
#Epoch 19/20 â€” LR: 0.000100 | Train Loss: 0.3689 | Val Loss: 0.5925 | Val Acc: 0.8373 | ROC-AUC: 0.9378 | PR-AUC: 0.9136

import os
import pandas as pd
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
from tqdm import tqdm

# 1) Paths and device
device       = torch.device("cuda" if torch.cuda.is_available() else "cpu")
bf_test_root = "/content/data/BF/test"
fl_test_root = "/content/data/FL/test"
checkpoint   = "best_model.pth"             # where you saved your best model
output_csv   = "submission.csv"

# 2) Get the list of test filenames (assumes BF and FL share the same names)
all_names = sorted(os.listdir(bf_test_root))

# 3) Define a test Dataset that ignores labels
class EarlyFusionTestDataset(Dataset):
    def __init__(self, names, bf_root, fl_root, joint_transform):
        self.names = names
        self.bf_root = bf_root
        self.fl_root = fl_root
        self.joint_transform = joint_transform
        self.to_tensor = transforms.ToTensor()

    def __len__(self):
        return len(self.names)

    def __getitem__(self, idx):
        name = self.names[idx]
        # load both modalities
        bf = Image.open(os.path.join(self.bf_root, name)).convert("RGB")
        fl = Image.open(os.path.join(self.fl_root, name)).convert("RGB")
        # to tensor
        bf = self.to_tensor(bf)
        fl = self.to_tensor(fl)
        # fuse channels
        x = torch.cat([bf, fl], dim=0)         # [6, H, W]
        # resize + normalize
        x = self.joint_transform(x)
        return x, name

# 4) Re-create the joint_transform exactly as in validation
#    (using the bf_mean, bf_std, fl_mean, fl_std you computed earlier)
mean = bf_mean + fl_mean
std  = bf_std  + fl_std

joint_transform = transforms.Compose([
    # note: these transforms accept and return a Tensor
    transforms.Resize((224, 224)),    # on torch.Tensor, this uses interpolate
    transforms.Normalize(mean=mean, std=std),
])

# 5) Instantiate DataLoader
test_ds = EarlyFusionTestDataset(all_names, bf_test_root, fl_test_root, joint_transform)
test_loader = DataLoader(test_ds, batch_size=256, shuffle=False, num_workers=8, pin_memory=True)

# 6) Load your best model checkpoint
config = DeiTConfig.from_pretrained("facebook/deit-tiny-distilled-patch16-224")
config.num_channels = 6
config.num_labels   = 1
model = DeiTForImageClassification.from_pretrained(
    "facebook/deit-tiny-distilled-patch16-224",
    config=config,
    ignore_mismatched_sizes=True
)
ckpt = torch.load(checkpoint, map_location=device)
model.load_state_dict(ckpt["model_state"])
model.to(device)
model.eval()

# 7) Run inference
results = []
with torch.no_grad():
    for x_batch, names_batch in tqdm(test_loader, desc="Inference"):
        x_batch = x_batch.to(device)
        logits  = model(x_batch).logits.squeeze(1)   # [B]
        probs   = torch.sigmoid(logits).cpu().tolist()
        results.extend(zip(names_batch, probs))

# 8) Build submission DataFrame and save, preserving order
df_sub = pd.DataFrame(results, columns=["Name", "Diagnosis"])
df_sub = df_sub.set_index("Name").loc[all_names].reset_index()
df_sub.to_csv(output_csv, index=False)

print(f"Saved {output_csv} with {len(df_sub)} rows.")